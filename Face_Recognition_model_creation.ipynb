{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------\n",
    "# Face Recognition model creation\n",
    "## ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                         # for Computer Vission\n",
    "import numpy as np \n",
    "from os import listdir             # to run OS commands\n",
    "from os.path import isfile, join   # To use paths of OS module\n",
    "import os                          # to run OS commands\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  # Load Model to detect a faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------------------------------------------------------------------\n",
    "# Person1 and Person2 model training\n",
    "## ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Person1 and Person2 Samples\n",
    "## -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "----------------------------------------\n",
      "\n",
      "Collecting Person1 Samples Completed.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Person1 Model trained sucessefully.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Person1 trained model is saved in path *./saved_model/person1_model.yml *\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Collecting Person2 Samples Completed.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Person2 Model trained sucessefully.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Person2 trained model is saved in path *./saved_model/person2_model.yml *\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class create_train:\n",
    "    def __init__(self, person=\"1\"):\n",
    "        person_model = \"\"\n",
    "        self.person = person\n",
    "        self.person_model = person_model\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        count = 0\n",
    "        self.displayTrain = lambda: print(f\"{'-'*40}\\n\\nPerson{self.person} Model trained sucessefully.\\n\\n{'-'*40}\\n\")\n",
    "        self.displaySample = lambda: print(f\"{'-'*40}\\n\\nCollecting Person{self.person} Samples Completed.\\n\\n{'-'*40}\\n\")\n",
    "        self.displaySave = lambda: print(f\"{'-'*40}\\n\\nPerson{self.person} trained model is saved in path *./saved_model/person{self.person}_model.yml *\\n\\n{'-'*40}\\n\")                          \n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    def face_extractor(self,img):   \n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  # Converts from 3d to 2d i.e., color to gray(white n black) \n",
    "        faces = face_classifier.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)   \n",
    "        # Detects face\n",
    "    #   scaleFactor      Parameter specifying how much the image size is reduced at each image scale.\n",
    "    #   minNeighbors: higher value results in less detections but with higher quality. \n",
    "        if faces is (): # returns none when no face found\n",
    "            return None\n",
    "        # Crop all faces found\n",
    "        for (x,y,w,h) in faces: # x= Xaxis,y=Yaxis, w=width,h=height\n",
    "            cropped_face = img[y:y+h, x:x+w] # Croping image start from Y axis till height(h), start from X axis till width(w)\n",
    "        return cropped_face                       \n",
    "    # Collect 100 samples of your face from webcam input\n",
    "    def sample(self):\n",
    "        cap = cv2.VideoCapture(0)    # Initialize Webcam\n",
    "        count = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()  # Capture image\n",
    "            if ret:\n",
    "                if self.face_extractor(frame) is not None: # Call function if image present thn run below lines\n",
    "                    count += 1  \n",
    "                    face = cv2.resize(self.face_extractor(frame), (200, 200))    # resize window\n",
    "                    face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)           # Convert to gray image\n",
    "\n",
    "                    # Save file in specified directory with unique name\n",
    "                    file_name_path = f'./faces/person{self.person}/' + str(count) + '.jpg'\n",
    "                    cv2.imwrite(file_name_path, face)\n",
    "\n",
    "                    # Put count on images and display live count\n",
    "                    cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                    cv2.imshow('Face Cropper', face)\n",
    "                else:\n",
    "                    print(\"Face not found\")\n",
    "                    pass\n",
    "            else:\n",
    "                break\n",
    "            if cv2.waitKey(1) == 13 or count == 200: #13 is the Enter Key\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()    # Stop windows\n",
    "        self.displaySample()\n",
    "    def train_model(self):\n",
    "        data_path = f'./faces/person{ self.person }/'          # Get the training data we previously made\n",
    "        onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))] # Collect Image names \n",
    "#         onlyfiles.remove(\".gitkeep\") # After Cloning uncomment this\n",
    "        Training_Data, Labels = [], []         # Create arrays for training data and labels\n",
    "        for i, files in enumerate(onlyfiles):         # Open training images in our datapath # Create a numpy array for training data\n",
    "            image_path = data_path + onlyfiles[i] # COmbine path and Image name\n",
    "            images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            Training_Data.append(np.asarray(images, dtype=np.uint8))  # Store image to data in array --> asarray\n",
    "            Labels.append(i)  # Append labels 1-200\n",
    "        Labels = np.asarray(Labels, dtype=np.int32)        # Create a numpy array for both training data and labels\n",
    "        # Initialize facial recognizer\n",
    "        # model = cv2.face.createLBPHFaceRecognizer()\n",
    "        # NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "        # pip install opencv-contrib-python\n",
    "        # model = cv2.createLBPHFaceRecognizer()\n",
    "        self.person_model  = cv2.face_LBPHFaceRecognizer.create() # Create A model for images\n",
    "        self.person_model.train(np.asarray(Training_Data), np.asarray(Labels))        # Let's train our model \n",
    "        self.displayTrain()\n",
    "    def save_model(self): # save model to file\n",
    "        self.person_model.save(f'./saved_model/person{self.person}_model.yml')\n",
    "        self.displaySave() \n",
    "person1 = create_train(\"1\") # call function to take sample\n",
    "person1.sample()\n",
    "person1.train_model()\n",
    "person1.save_model()\n",
    "person2 = create_train(\"2\")\n",
    "person2.sample()\n",
    "person2.train_model()\n",
    "person2.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
